{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "clear-marble",
   "metadata": {},
   "source": [
    "# Training main:\n",
    "\n",
    "take from cyanite notebook the interface to observe tags distribution and create datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "municipal-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from frontend import Frontend_mine, Frontend_won\n",
    "from backend import Backend, Backend2\n",
    "from data_loader import get_DataLoader\n",
    "\n",
    "main_dict = {\"frontend_dict\":\n",
    "             {\"list_out_channels\":[128,128,256,256,256,256], \n",
    "              \"list_kernel_sizes\":[(3,3),(3,3),(3,3),(3,3),(3,3),(3,3)],\n",
    "              \"list_pool_sizes\":  [(3,1),(2,2),(2,2),(2,1),(2,1),(2,1)], \n",
    "              \"list_avgpool_flags\":[False,False,False,False,False,True]},\n",
    "             \n",
    "             \"backend_dict\":\n",
    "             {\"n_class\":50,\n",
    "              \"bert_config\":None, \n",
    "              \"recurrent_units\":2}} # pass None to deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "nasty-gilbert",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNNSA(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    TODO: explore whether \"rec_unit -> self_att -> rec_unit\"\n",
    "    would have worked better.\n",
    "    \"\"\"\n",
    "    \n",
    "    # BERT-based Convolutional Recurrent Neural Network\n",
    "    # Code adopted from https://github.com/minzwon/sota-music-tagging-models/\n",
    "    def __init__(self, main_dict=None, backend=None, frontend=None):\n",
    "        super(CRNNSA, self).__init__()\n",
    "        \n",
    "\n",
    "        if main_dict is not None:\n",
    "            self.frontend = Frontend_mine(main_dict[\"frontend_dict\"])\n",
    "            self.backend = Backend2(main_dict)\n",
    "        else:\n",
    "            self.frontend = frontend\n",
    "            self.backend = backend\n",
    "\n",
    "\n",
    "    def forward(self, spec):\n",
    "        \n",
    "        x = self.backend(self.frontend(spec))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "endless-change",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRNNSA(\n",
      "  (frontend): Frontend_mine(\n",
      "    (spec_bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_block1): BlockChoi(\n",
      "      (conv): Conv2dSame(1, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ELU(alpha=1.0)\n",
      "      (pool): MaxPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (conv_block2): BlockChoi(\n",
      "      (conv): Conv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ELU(alpha=1.0)\n",
      "      (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (conv_block3): BlockChoi(\n",
      "      (conv): Conv2dSame(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ELU(alpha=1.0)\n",
      "      (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (conv_block4): BlockChoi(\n",
      "      (conv): Conv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ELU(alpha=1.0)\n",
      "      (pool): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (conv_block5): BlockChoi(\n",
      "      (conv): Conv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ELU(alpha=1.0)\n",
      "      (pool): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (conv_block6): BlockChoi(\n",
      "      (conv): Conv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ELU(alpha=1.0)\n",
      "      (pool): AvgPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (backend): Backend2(\n",
      "    (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dense1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (dense2): Linear(in_features=256, out_features=50, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "crnnsa = CRNNSA(main_dict)\n",
    "print(crnnsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "following-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 5\n",
    "input_length = int(input_length*16000/256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "changed-italy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 96, 312])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec = torch.FloatTensor(np.load(\"/import/c4dm-datasets/rmri_self_att/msd/1/1/113801.npy\")[np.newaxis,\n",
    "                                                                                           np.newaxis,\n",
    "                                                                                           :,\n",
    "                                                                                           :input_length])\n",
    "spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "average-saint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 48])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://towardsdatascience.com/temporal-convolutional-networks-the-next-revolution-for-time-series-8990af826567\n",
    "x = nn.Conv1d(256,256, 3)(crnnsa.frontend(spec))\n",
    "x = nn.Conv1d(256,256, 3, dilation=2)(x)\n",
    "x = nn.Conv1d(256,256, 3, dilation=4)(x)\n",
    "x = nn.Conv1d(256,256, 3, dilation=8)(x)\n",
    "x.shape\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "silent-partition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 312])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crnnsa.frontend(spec).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "manufactured-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader = get_DataLoader(batch_size=1, input_length=5, mode=\"valid\", num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adjustable-bearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 96, 312])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 6, 96, 312])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 12, 96, 312])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 12, 96, 312])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 12, 96, 312])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 12, 96, 312])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 6, 96, 312])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 6, 96, 312])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 12, 96, 312])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 12, 96, 312])\n",
      "torch.Size([1, 50])\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for x,y in dataLoader:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    ctr+=1\n",
    "    if ctr==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "greatest-volume",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6fd5db912c3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrnnsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrontend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrnnsa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "print(crnnsa.frontend(x).shape)\n",
    "print(crnnsa(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_spec = np.load(\"/import/c4dm-datasets/rmri_self_att/msd/1/1/113801.npy\")\n",
    "\n",
    "n_chunks = whole_spec.shape[1] // input_length\n",
    "spec = np.zeros((n_chunks,whole_spec.shape[0],input_length))\n",
    "for i in range(n_chunks):\n",
    "    spec[i]=whole_spec[:,i*input_length:(i+1)*input_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_spec.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4am",
   "language": "python",
   "name": "dl4am"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
