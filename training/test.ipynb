{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "downtown-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from frontend import Frontend_mine, Frontend_won\n",
    "from backend import Backend\n",
    "from data_loader import get_DataLoader\n",
    "import datetime\n",
    "\n",
    "from main import AssembleModel\n",
    "\n",
    "# define here all the parameters\n",
    "main_dict = {\"frontend_dict\":\n",
    "             {\"list_out_channels\":[128,128,256,256,256,256], \n",
    "              \"list_kernel_sizes\":[(3,3),(3,3),(3,3),(3,3),(3,3),(3,3)],\n",
    "              \"list_pool_sizes\":  [(3,2),(2,2),(2,2),(2,1),(2,1),(2,1)], \n",
    "              \"list_avgpool_flags\":[False,False,False,False,False,True]},\n",
    "             \n",
    "             \"backend_dict\":\n",
    "             {\"n_class\":50,\n",
    "              \"bert_config\":None, \n",
    "              \"recurrent_units\":2, \n",
    "              \"bidirectional\":True}, #  pass recurrent_units = None to deactivate\n",
    "             \n",
    "             \"training_dict\":\n",
    "             {\"dataset\":'msd',\n",
    "              \"architecture\":'without_seq2seq_5s',\n",
    "              \"n_epochs\":1000,\n",
    "              \"learning_rate\":1e-4},\n",
    "             \n",
    "             \"data_loader_dict\":\n",
    "             {\"path_to_repo\":'~/dl4am/',\n",
    "              \"batch_size\":128,\n",
    "              \"input_length\":5, # [s]\n",
    "              \"spec_path\":'/import/c4dm-datasets/rmri_self_att/msd',\n",
    "              \"audio_path\":'/import/c4dm-03/Databases/songs/',\n",
    "              \"mode\":'train', \n",
    "              \"num_workers\":20}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pacific-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parameters(model, filename): \n",
    "    model = torch.nn.DataParallel(model)\n",
    "    S = torch.load(filename)\n",
    "    model.load_state_dict(S)\n",
    "    return model\n",
    "\n",
    "def test(model, data_loader):\n",
    "    model.eval()\n",
    "    y_score = []\n",
    "    y_true = []\n",
    "    ctr = 0\n",
    "    for x,y in data_loader:\n",
    "        ctr+=1\n",
    "\n",
    "        # NB: in validation mode the output of the DataLoader\n",
    "        # has a shape of (1,n_chunks,F,T), where n_chunks = total time frames // input_length\n",
    "        x = x.permute(1,0,2,3) \n",
    "        # by permuting it here we are treating n_chunks as the batch_size\n",
    "\n",
    "        # forward\n",
    "        out = model(x)\n",
    "        out = out.detach().cpu()\n",
    "\n",
    "        y_score.append(out.numpy().mean(axis=0))\n",
    "\n",
    "        y_true.append(y.detach().numpy())\n",
    "\n",
    "        if ctr % 1000 == 0:\n",
    "            print(\"[%s] Valid Iter [%d/%d] \" %\n",
    "                  (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                   ctr, len(data_loader)))\n",
    "\n",
    "    y_score = np.array(y_score).squeeze()\n",
    "    y_true = np.array(y_true).squeeze().astype(int)\n",
    "\n",
    "    roc_auc  = metrics.roc_auc_score(y_true, y_score, average='macro')\n",
    "    pr_auc = metrics.average_precision_score(y_true, y_score, average='macro')\n",
    "    print('roc_auc: %.4f' % roc_auc)\n",
    "    print('pr_auc: %.4f' % pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "textile-sitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28435"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = get_DataLoader(batch_size=1, input_length=5, mode='test', num_workers=10)\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "international-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional_recurrent_self_att = load_parameters(AssembleModel(main_dict),\"../models/best_model_bidirectional.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "royal-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dict[\"backend_dict\"][\"bidirectional\"] = False\n",
    "recurrent_self_att = load_parameters(AssembleModel(main_dict),\"../models/best_model_sacrnn_5s.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "imported-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dict[\"backend_dict\"][\"recurrent_units\"] = None\n",
    "only_self_att = load_parameters(AssembleModel(main_dict),\"../models/best_model_no_recurrent.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unknown-deposit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-14 11:14:43] Valid Iter [1000/28435] \n",
      "[2021-03-14 11:14:59] Valid Iter [2000/28435] \n",
      "[2021-03-14 11:15:15] Valid Iter [3000/28435] \n",
      "[2021-03-14 11:15:30] Valid Iter [4000/28435] \n",
      "[2021-03-14 11:15:46] Valid Iter [5000/28435] \n",
      "[2021-03-14 11:16:02] Valid Iter [6000/28435] \n",
      "[2021-03-14 11:16:17] Valid Iter [7000/28435] \n",
      "[2021-03-14 11:16:33] Valid Iter [8000/28435] \n",
      "[2021-03-14 11:16:48] Valid Iter [9000/28435] \n",
      "[2021-03-14 11:17:04] Valid Iter [10000/28435] \n",
      "[2021-03-14 11:17:20] Valid Iter [11000/28435] \n",
      "[2021-03-14 11:17:35] Valid Iter [12000/28435] \n",
      "[2021-03-14 11:17:51] Valid Iter [13000/28435] \n",
      "[2021-03-14 11:18:07] Valid Iter [14000/28435] \n",
      "[2021-03-14 11:18:22] Valid Iter [15000/28435] \n",
      "[2021-03-14 11:18:37] Valid Iter [16000/28435] \n",
      "[2021-03-14 11:18:52] Valid Iter [17000/28435] \n",
      "[2021-03-14 11:19:07] Valid Iter [18000/28435] \n",
      "[2021-03-14 11:19:22] Valid Iter [19000/28435] \n",
      "[2021-03-14 11:19:38] Valid Iter [20000/28435] \n",
      "[2021-03-14 11:19:53] Valid Iter [21000/28435] \n",
      "[2021-03-14 11:20:08] Valid Iter [22000/28435] \n",
      "[2021-03-14 11:20:23] Valid Iter [23000/28435] \n",
      "[2021-03-14 11:20:39] Valid Iter [24000/28435] \n",
      "[2021-03-14 11:20:54] Valid Iter [25000/28435] \n",
      "[2021-03-14 11:21:10] Valid Iter [26000/28435] \n",
      "[2021-03-14 11:21:25] Valid Iter [27000/28435] \n",
      "[2021-03-14 11:21:40] Valid Iter [28000/28435] \n",
      "roc_auc: 0.8914\n",
      "pr_auc: 0.3280\n"
     ]
    }
   ],
   "source": [
    "test(bidirectional_recurrent_self_att,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aggregate-cache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-12 16:18:31] Valid Iter [1000/28435] \n",
      "[2021-03-12 16:18:45] Valid Iter [2000/28435] \n",
      "[2021-03-12 16:18:59] Valid Iter [3000/28435] \n",
      "[2021-03-12 16:19:13] Valid Iter [4000/28435] \n",
      "[2021-03-12 16:19:28] Valid Iter [5000/28435] \n",
      "[2021-03-12 16:19:42] Valid Iter [6000/28435] \n",
      "[2021-03-12 16:19:56] Valid Iter [7000/28435] \n",
      "[2021-03-12 16:20:10] Valid Iter [8000/28435] \n",
      "[2021-03-12 16:20:25] Valid Iter [9000/28435] \n",
      "[2021-03-12 16:20:39] Valid Iter [10000/28435] \n",
      "[2021-03-12 16:20:53] Valid Iter [11000/28435] \n",
      "[2021-03-12 16:21:08] Valid Iter [12000/28435] \n",
      "[2021-03-12 16:21:22] Valid Iter [13000/28435] \n",
      "[2021-03-12 16:21:36] Valid Iter [14000/28435] \n",
      "[2021-03-12 16:21:50] Valid Iter [15000/28435] \n",
      "[2021-03-12 16:22:05] Valid Iter [16000/28435] \n",
      "[2021-03-12 16:22:19] Valid Iter [17000/28435] \n",
      "[2021-03-12 16:22:33] Valid Iter [18000/28435] \n",
      "[2021-03-12 16:22:47] Valid Iter [19000/28435] \n",
      "[2021-03-12 16:23:02] Valid Iter [20000/28435] \n",
      "[2021-03-12 16:23:16] Valid Iter [21000/28435] \n",
      "[2021-03-12 16:23:30] Valid Iter [22000/28435] \n",
      "[2021-03-12 16:23:45] Valid Iter [23000/28435] \n",
      "[2021-03-12 16:23:59] Valid Iter [24000/28435] \n",
      "[2021-03-12 16:24:13] Valid Iter [25000/28435] \n",
      "[2021-03-12 16:24:27] Valid Iter [26000/28435] \n",
      "[2021-03-12 16:24:42] Valid Iter [27000/28435] \n",
      "[2021-03-12 16:24:56] Valid Iter [28000/28435] \n",
      "roc_auc: 0.8919\n",
      "pr_auc: 0.3294\n"
     ]
    }
   ],
   "source": [
    "test(recurrent_self_att,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "qualified-excuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-12 16:25:18] Valid Iter [1000/28435] \n",
      "[2021-03-12 16:25:31] Valid Iter [2000/28435] \n",
      "[2021-03-12 16:25:45] Valid Iter [3000/28435] \n",
      "[2021-03-12 16:25:59] Valid Iter [4000/28435] \n",
      "[2021-03-12 16:26:13] Valid Iter [5000/28435] \n",
      "[2021-03-12 16:26:26] Valid Iter [6000/28435] \n",
      "[2021-03-12 16:26:40] Valid Iter [7000/28435] \n",
      "[2021-03-12 16:26:54] Valid Iter [8000/28435] \n",
      "[2021-03-12 16:27:08] Valid Iter [9000/28435] \n",
      "[2021-03-12 16:27:22] Valid Iter [10000/28435] \n",
      "[2021-03-12 16:27:35] Valid Iter [11000/28435] \n",
      "[2021-03-12 16:27:49] Valid Iter [12000/28435] \n",
      "[2021-03-12 16:28:02] Valid Iter [13000/28435] \n",
      "[2021-03-12 16:28:16] Valid Iter [14000/28435] \n",
      "[2021-03-12 16:28:29] Valid Iter [15000/28435] \n",
      "[2021-03-12 16:28:43] Valid Iter [16000/28435] \n",
      "[2021-03-12 16:28:56] Valid Iter [17000/28435] \n",
      "[2021-03-12 16:29:09] Valid Iter [18000/28435] \n",
      "[2021-03-12 16:29:23] Valid Iter [19000/28435] \n",
      "[2021-03-12 16:29:36] Valid Iter [20000/28435] \n",
      "[2021-03-12 16:29:49] Valid Iter [21000/28435] \n",
      "[2021-03-12 16:30:03] Valid Iter [22000/28435] \n",
      "[2021-03-12 16:30:16] Valid Iter [23000/28435] \n",
      "[2021-03-12 16:30:29] Valid Iter [24000/28435] \n",
      "[2021-03-12 16:30:42] Valid Iter [25000/28435] \n",
      "[2021-03-12 16:30:56] Valid Iter [26000/28435] \n",
      "[2021-03-12 16:31:09] Valid Iter [27000/28435] \n",
      "[2021-03-12 16:31:22] Valid Iter [28000/28435] \n",
      "roc_auc: 0.8922\n",
      "pr_auc: 0.3294\n"
     ]
    }
   ],
   "source": [
    "test(only_self_att,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "appreciated-belfast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5715124\n",
      "4925620\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in recurrent_self_att.parameters()))\n",
    "print(sum(p.numel() for p in only_self_att.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-singer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4am",
   "language": "python",
   "name": "dl4am"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
